\documentclass[a4paper,twoside]{article}

\usepackage{listings}
\usepackage{color}
\usepackage{xcolor}
\usepackage{tikz}

\usetikzlibrary{positioning}
\usetikzlibrary{shapes,decorations,shadows}

\begin{document}
\title{Concurrent Memory Reclamation on ARM}
\author{Martin Hafskjold Thoresen}
\date{\today}
\maketitle

\input{macros.latex}

\begin{abstract}
  Concurrent programs, like any other program, produces garbage.
  In languages that do not have a garbage collector, freeing used
  memory needs to be handeled by the programmer, or through other
  means by the language.
  This report compares 3 different memory reclamation schemes:
  epoch based reclamation, hazard pointers, and reference counting.
  We look at how they perform when used in different common concurrent
  data structures, such as Queues, Lists, and (probably not) Skip-Lists,
  on the ARM platform.
\end{abstract}

\section{Introduction}

\tableofcontents

\section{Background}
What do we need to understand in order to appreciate this report?
Moores law, parallel applications, multi core, blabla

Something about ARM.

\subsection{Rust}
% New programming language, memory safety without GC, etc.
\todo{This doesn't read very well. Fix.}
Rust is a programming language which focus is safety, speed, and concurrency.
It originally emerged from Mozilla Labs in \todo{20??} but is now freely developed
by over \todo{12345} contributors.
Version 1.0 was released in May 2015, and the current stable version is 1.21.
The language is compiled and typed, and features
type inference and virtually no runtime.

The language differs from most other languages in that it features linear types
by its \emph{ownership} semantics.
Values are either \emph{owned} or \emph{borrowed} by its scope.
When an owned value goes out of scope Rust's ownership rules guarantees that
there are no other references to the object and it can be safely \emph{dropped}
by running its destructor when applicable.
This way the programmer does not have to manually manage memory.

\subsubsection{A Crash Course in Rust}

Rust's syntax is based on that of C and OCaml.
Variable bindings are created with the \code{let} construct,
and they are immutable by default, unless marked with \code{mut}.
Functions are declared with \code{fn}, and blocks are surrounded by curly brackets.
The scope operator is \code{::}.

Almost all syntactic constructs in Rust are expressions, including blocks and
\code{if} statements.
Expressions terminated by a semicolon have the value of \emph{unit} (\code{()}).
The return value of a function is the value of its block, which again is the final
expression in the block. Alternatively we can use \code{return}, as in C.
Similiar to C++, Rust programmers prefers \emph{references} over raw pointers.
We use \code{\&} and \code{*} as in C and C++.
As with variables references are immutable by default; ie. the value they point
to cannot be mutated.

\begin{lstlisting}[firstnumber=last]
// ERROR:
fn add_five(arg: &u32) { *arg += 5; }
// OK:
fn add_five(arg: &mut u32) { *arg += 5; }
\end{lstlisting}

Mutable references cannot alias; that is, it is not allowed to have multiple \code{\&mut}
to the same data, and it is not allowed to have one \code{\&mut} in addition to other
references.

References are guaranteed to be valid, through Rusts usage of \emph{lifetimes}.
A reference is only allowed to live for as long as the data it points to.
This makes it impossible to return a reference to local stack variable in a function:
\begin{lstlisting}[firstnumber=last]
fn add_five() -> &u32 { let n: u32 = 1; &n } // ERROR
\end{lstlisting}

A central point of Rusts philosophy is to build safe abtractions for programmers to use.
For instance, \code{std::box::Box<T>} is a type that heap allocates a value of type \code{T}.
The constructor will allocate the memory, and the destructor will free the memory.
Since references can never outlive the value it references, any other pointer to the value
is guaranteed by the compiler to be valid.
This way we get a safe abtraction over heap allocation.

Through lifetime tracking and the ownership model, Rust avoids the need for a
garbage collector, while still allowing the programmer to not handle memory
management directly. It does however add to the programmers mental overhead,
since lifetime constraints and ownerships of the data must be tracked by their
the mental model.

\note{Add links to The Book ++}

\todo{A longer code example, comparing Rust to C++17?}


\subsubsection{}
\note{Show of why Rust is interesting, eg. how the abstractions can be used,
and why it makes sense to look at Rust.}
\todo{Title of the subchapter}
\todo{Ordering of this stuff}
While Rust features rather strict rules for ownership and lifetimes of all values,
the programmer may bend these rules as they wish.
For instance it is possible to leak a value by not running its destructor,
by using the \code{std::mem::forget} function, or to explicitly run the destrutor of
a value, by calling \code{std::mem::drop}.

Rust also have \emph{raw pointers}, which behaves like regular pointers in C and C++.
Copying and creating raw pointers are safe operations, but reading a raw pointer is
\code{unsafe}, as there are no guarantee on the memory we are reading.

\todo{raw pointers, safe abstractions, some other things.}


\section{Memory Reclamation}
\note{What is memory reclamation? Why is it hard? What approaches are there?}

When programming we lend memory from the operating system. This memory must be returned, or else
we will sooner or later run out of it.
In most modern programming languages, this is a feature provided by the runtime of the language.
We call such languages \emph{managed languages}.
However, in languages such as Rust, there is virtually no runtime, so this becomes a concern
of the programmer.
Garbage colleciton is typically the name used for memory reclamation;
if we want to pedantic we would say a garbage collector performs memory reclamation.

In a concurrent setting, we are concerned about the properties of our data structures,
\todo{define this}
such as wait-freedom, or lock-freedom.
\todo{rewrite this sentence}
One can make the claim that data structures implemented in managed languages can never
obtain some of these properties, since they depend on the runtime to get execution time
in order for the program to be able to allocate memory.
Hence, the runtime thread has to get CPU time in order for the program to make progress.
\note{Could say this better; the point is to motivate the usage of Rust.}

The field of concurrent memory reclamation is an active one, and a lot of different schemes
have emerged the recent years. We will look at
\emph{Reference Counting} (RC),
\emph{Epoch Based Reclamation} (EBR),
\emph{Hazard Pointers} (HP),
\note{and maybe a few others?}




\subsection{Reference Counting}
\todo{this}
Simple, "obvious" solution. But does it work?

\todo{split into two paragraphs? Eventually move history part to bottom}
The idea of reference counting is that we count the number of references to data,
so that we can tell if we are holding the only reference to some data.
When we no longer need this reference, we know it is safe to reclaim the memory
the reference points to, since no other reference to that memory exists.
Reference counting first appeared in 1960 by G. E. Collins\cite{collins1960},
where it was used for collecting nodes of a linked list.
The primary downsides of RC is that it is rather expensive, and that a na\"ive
implementation does not reclaim cycles.
Today reference counting is still used, although not in the setting of general
memory reclamation. \todo{source?}
\note{Want to say that while RC isn't used in GC, it is used for other things, like
\code{std::rc::Rc} stuff. Also \code{Arc}, even more expensive}.

% TODO: Use this for node drawing, when needed.
%
% \begin{figure}[ht]
% \begin{tikzpicture}
% \tikzset{Node/.style={
%   rectangle split,
%   rectangle split horizontal,
%   rectangle split parts=2,
%   draw,
%   rounded corners=0.1cm
%   }}
%       \node [Node] (A) at (0,0) {\code{Count=3} \nodepart{second} \code{DATA} };\\
%       \node [Node] (B) at (4,0) {\code{Count} \nodepart{second} \code{DATA} };\\
%       \draw[->]  (0.5,-1) -- (0.5,-0.3);
%       \draw[->]  (0,-1) -- (0,-0.3);
%       \draw[->]  (-0.5,-1) -- (-0.5,-0.3);
% \end{tikzpicture}
%   \caption{Data nodes using RC}
% \end{figure}

\todo{Consider adding a code listing instead of using words}
Reference counting is a natural approach to the problem of concurrent memory reclamation.
The first observation to make is that we need to use atomic reads and writes
to correctly increment and decrement the reference count. However,
the na\"ive implementation is not correct.
Consider two threads operating on some \code{RC<T>}.
When thread A want to create a new reference to the data, it increments the count in
the \code{RC} object. Upon destruction, the count is decremented
and the data is freed if the count is 0.
However, it is possible that thread B has a reference to the RC object
and that it got preempted right before incrementing the count.
Then the whole object gets freed by thread A, since the count is 0,
and when thread B gets execution time again, it has a pointer to freed memory
which it indents to read.
It is worth noting that we can free the \emph{data} using this scheme, but not
the entire \code{RC} node.

\note{Add note on differential RC:
http://www.1024cores.net/home/lock-free-algorithms/object-life-time-management/differential-reference-counting}


% TODO:  Code listing sample here, with custom lineno prefix
%
% \begin{lstlisting}[label=lst:rc-broken,
%                    numberblanklines=false,
%                    % TODO: would like to not copy this all over the place
%                    numberstyle=\color{gray}\ttfamily{}RC]
% node = load_node();
% node.count += 1;
% data = node.data;
% // use the node
% node.count -=1;
% if node.count == 0
%   free(node);
% \end{lstlisting}

\subsection{Epoch Based Reclamation}

\todo{history of EBR}

EBR is a reclamation scheme based on the observation that most programs have no
references to data structure nodes in between of operations on said structure,
such that a given thread has no references to memory managed by the data strcutre
in between operations on it.

We use a global counter to store an \emph{epoch}, and each thread has a local
version of the epoch they last saw.
Before an operation the thread reads the global epoch, and stores it in its local
memory, as well as registering that we are performing an operation.
When the thread wants to free memory it markes it with the current epoch
and puts it in a \emph{limbo list}.

We may increment the epoch by looking at all threads; if all threads that are currently
performing an operation have seen the current global epoch, we may increment it.
Upon epoch incrementation to epoch $e$, memory put in the limbo list at epoch $e-2$ is
safe to free \note{why?}.

\todo{Limits/challenges of EBR}

\subsection{Hazard Pointers}
\todo{history of HP}

In most operations on data structure, we only need a small constant number of
references to shared memory. Hazard pointers exploits this by allowing each
thread to reigster $n$ \emph{hazard pointers} which it needs to perform its operation.
For instance, if we traverse a linked list, the thread would register the pointers
to the nodes it visites and the next node \note{what?}.
$n$ is typically a low number, such as $3$ or $5$.


\subsection{Other Schemes}
\note{We don't have time to implement all interesting schemes,
but it would be nice to have them in the report}



\section{Results}
What did we run? Plot some graphs. What did we find out?
Which scheme is better for which application?
Runtime, power usage, etc.

\section{Discussion}
Whys

\bibliographystyle{acm}
\bibliography{sources}

\end{document}
